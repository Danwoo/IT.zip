{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11431,"status":"ok","timestamp":1685635700064,"user":{"displayName":"서단우","userId":"02276360755929024305"},"user_tz":-540},"id":"LqKsNV5OzZ6Y","outputId":"403fffb6-8922-4e7c-a2c1-c485228d2101"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/요약 데이터\n"]}],"source":["%cd /content/drive/MyDrive/요약 데이터"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGHcVRPP3SuX"},"outputs":[],"source":["import os\n","import io\n","import pandas as pd\n","import json"]},{"cell_type":"markdown","source":["# 1.문서요약 텍스트"],"metadata":{"id":"ZOvfksT8m7u4"}},{"cell_type":"code","source":["def combine_json_files_recursive(folder_path):\n","    data_frames = []\n","\n","    # Traverse the directory recursively\n","    for root, dirs, files in os.walk(folder_path):\n","        for file_name in files:\n","            file_path = os.path.join(root, file_name)\n","\n","            # Check if the file is a JSON file\n","            if file_name.endswith('.json') and os.path.isfile(file_path):\n","                # Read JSON file into a DataFrame\n","                with open(file_path, 'r') as file:\n","                    json_data = json.load(file)\n","                    df = pd.DataFrame(json_data['documents'])\n","\n","                # Check for duplicate column names\n","                duplicates = df.columns[df.columns.duplicated()]\n","                for duplicate in duplicates:\n","                    # Add suffix to distinguish duplicate column names\n","                    suffix = 1\n","                    while duplicate + '_' + str(suffix) in df.columns:\n","                        suffix += 1\n","                    df.rename(columns={duplicate: duplicate + '_' + str(suffix)}, inplace=True)\n","\n","                # Append DataFrame to the list\n","                data_frames.append(df)\n","\n","    # Concatenate all DataFrames into a single DataFrame\n","    combined_df = pd.concat(data_frames, ignore_index=True)\n","\n","    return combined_df\n","\n","folder_path = '1.문서요약 텍스트'\n","combined_df = combine_json_files_recursive(folder_path)\n","data_문서 = combined_df[['text','abstractive']]"],"metadata":{"id":"HtXSW1swkcdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_문서.to_csv('document.csv')"],"metadata":{"id":"TwJF1xyhrAQ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4.논문자료 요약"],"metadata":{"id":"f5pLSJ9nm_P2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7caG1gYfWsv"},"outputs":[],"source":["class JSONDataProcessor:\n","    def __init__(self, root_folder):\n","        \"\"\"\n","        JSONDataProcessor 클래스를 초기화합니다.\n","\n","        Args:\n","            root_folder (str): JSON 파일들이 포함된 최상위 폴더의 경로.\n","        \"\"\"\n","        self.root_folder = root_folder\n","\n","    def combine_json_files(self):\n","        \"\"\"\n","        주어진 폴더 안에 있는 모든 JSON 파일들을 읽어들여 데이터프레임으로 결합합니다.\n","\n","        Returns:\n","            pandas.DataFrame: JSON 파일들을 결합한 결과로 생성된 데이터프레임.\n","        \"\"\"\n","        dataframes = []\n","        for root, dirs, files in os.walk(self.root_folder):\n","            for file in files:\n","                if file.endswith('.json'):\n","                    file_path = os.path.join(root, file)\n","                    with open(file_path, 'r', encoding = 'UTF-8') as json_file:\n","                        json_data = json.load(json_file)\n","                        data = json_data['data']\n","                        df = pd.DataFrame(data)\n","                        dataframes.append(df)\n","\n","        combined_df = pd.concat(dataframes, ignore_index=True)\n","        return combined_df\n","\n","    def extract_summary_columns(self, combined_df, column_names):\n","        \"\"\"\n","        데이터프레임에서 주어진 컬럼들을 분리하여 해당 컬럼의 원소를 컬럼명으로 하는 새로운 데이터프레임을 생성합니다.\n","\n","        Args:\n","            combined_df (pandas.DataFrame): 분리를 수행할 대상 데이터프레임.\n","            column_names (list): 분리할 컬럼명들의 리스트.\n","\n","        Returns:\n","            pandas.DataFrame: 분리를 수행한 결과로 생성된 데이터프레임.\n","        \"\"\"\n","        for column_name in column_names:\n","            column_data = combined_df[column_name]\n","\n","            column_data_list = []\n","            for item in column_data:\n","                if isinstance(item, list):\n","                    column_data_list.append(item[0])\n","                else:\n","                    column_data_list.append(item)\n","\n","            new_df = pd.DataFrame(column_data_list)\n","            combined_df.drop(column_name, axis=1, inplace=True)\n","            combined_df = pd.concat([combined_df, new_df], axis=1)\n","\n","        return combined_df\n","\n","    def make_unique_column_names(self, df):\n","        \"\"\"\n","        데이터프레임의 컬럼명이 중복된 경우 고유한 컬럼명을 만들어줍니다.\n","\n","        Args:\n","            df (pandas.DataFrame): 중복된 컬럼명이 포함된 데이터프레임.\n","\n","        Returns:\n","            pandas.DataFrame: 컬럼명이 중복을 피한 데이터프레임.\n","        \"\"\"\n","        unique_columns = []\n","        for col in df.columns:\n","            if col in unique_columns:\n","                counter = 1\n","                new_col = f\"{col}_{counter}\"\n","                while new_col in unique_columns:\n","                    counter += 1\n","                    new_col = f\"{col}_{counter}\"\n","                unique_columns.append(new_col)\n","            else:\n","                unique_columns.append(col)\n","\n","        df.columns = unique_columns\n","        return df\n","\n","# Usage example:\n","folder_path = '/content/drive/MyDrive/요약 데이터/4.논문자료 요약'\n","data_processor = JSONDataProcessor(folder_path)\n","\n","combined_dataframe = data_processor.combine_json_files()\n","\n","columns_to_split = ['summary_entire', 'summary_section']\n","combined_dataframe = data_processor.extract_summary_columns(combined_dataframe, columns_to_split)\n","\n","combined_dataframe = data_processor.make_unique_column_names(combined_dataframe)\n","# 두 열(original, summary)을 세로로 쌓기\n","stacked_column_o = pd.concat([combined_dataframe['orginal_text'], combined_dataframe['orginal_text_1']], axis=0, ignore_index=True)\n","stacked_column_s = pd.concat([combined_dataframe['summary_text'], combined_dataframe['summary_text_1']], axis=0, ignore_index=True)\n","\n","# 쌓인 열을 사용하여 새 데이터 프레임 생성\n","data_논문 = pd.DataFrame({'original_text': stacked_column_o, 'summary_text': stacked_column_s})"]},{"cell_type":"code","source":["data_논문.to_csv('paper.csv')"],"metadata":{"id":"q1b9rVl7F8lJ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1UjiCTBddgCyZyFerI7cS7o00rSJnNEQr","authorship_tag":"ABX9TyP9ZnsFi7CO8v45R72TIkVt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}