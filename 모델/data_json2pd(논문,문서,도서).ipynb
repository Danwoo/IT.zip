{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11431,"status":"ok","timestamp":1685635700064,"user":{"displayName":"서단우","userId":"02276360755929024305"},"user_tz":-540},"id":"LqKsNV5OzZ6Y","outputId":"403fffb6-8922-4e7c-a2c1-c485228d2101"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/요약 데이터\n"]}],"source":["%cd /content/drive/MyDrive/요약 데이터"]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZryKk2eepbQ","executionInfo":{"status":"ok","timestamp":1685635700976,"user_tz":-540,"elapsed":926,"user":{"displayName":"서단우","userId":"02276360755929024305"}},"outputId":"1d619156-f426-4da6-f13a-b82684ca47c4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34m'1.문서요약 텍스트'\u001b[0m/  \u001b[01;34m'4.논문자료 요약'\u001b[0m/                     document.csv\n","\u001b[01;34m'2.도서자료 요약'\u001b[0m/    'data_json2pd(논문,문서,도서).ipynb'   paper.csv\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NGHcVRPP3SuX","executionInfo":{"status":"ok","timestamp":1685635708096,"user_tz":-540,"elapsed":7123,"user":{"displayName":"서단우","userId":"02276360755929024305"}}},"outputs":[],"source":["import os \n","import io\n","import pandas as pd\n","import json"]},{"cell_type":"markdown","source":["# 4.논문자료 요약"],"metadata":{"id":"f5pLSJ9nm_P2"}},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":53478,"status":"ok","timestamp":1685633922798,"user":{"displayName":"서단우","userId":"02276360755929024305"},"user_tz":-540},"id":"G7caG1gYfWsv"},"outputs":[],"source":["class JSONDataProcessor:\n","    def __init__(self, root_folder):\n","        \"\"\"\n","        JSONDataProcessor 클래스를 초기화합니다.\n","\n","        Args:\n","            root_folder (str): JSON 파일들이 포함된 최상위 폴더의 경로.\n","        \"\"\"\n","        self.root_folder = root_folder\n","\n","    def combine_json_files(self):\n","        \"\"\"\n","        주어진 폴더 안에 있는 모든 JSON 파일들을 읽어들여 데이터프레임으로 결합합니다.\n","\n","        Returns:\n","            pandas.DataFrame: JSON 파일들을 결합한 결과로 생성된 데이터프레임.\n","        \"\"\"\n","        dataframes = []\n","        for root, dirs, files in os.walk(self.root_folder):\n","            for file in files:\n","                if file.endswith('.json'):\n","                    file_path = os.path.join(root, file)\n","                    with open(file_path, 'r', encoding = 'UTF-8') as json_file:\n","                        json_data = json.load(json_file)\n","                        data = json_data['data']\n","                        df = pd.DataFrame(data)\n","                        dataframes.append(df)\n","\n","        combined_df = pd.concat(dataframes, ignore_index=True)\n","        return combined_df\n","\n","    def extract_summary_columns(self, combined_df, column_names):\n","        \"\"\"\n","        데이터프레임에서 주어진 컬럼들을 분리하여 해당 컬럼의 원소를 컬럼명으로 하는 새로운 데이터프레임을 생성합니다.\n","\n","        Args:\n","            combined_df (pandas.DataFrame): 분리를 수행할 대상 데이터프레임.\n","            column_names (list): 분리할 컬럼명들의 리스트.\n","\n","        Returns:\n","            pandas.DataFrame: 분리를 수행한 결과로 생성된 데이터프레임.\n","        \"\"\"\n","        for column_name in column_names:\n","            column_data = combined_df[column_name]\n","\n","            column_data_list = []\n","            for item in column_data:\n","                if isinstance(item, list):\n","                    column_data_list.append(item[0])\n","                else:\n","                    column_data_list.append(item)\n","\n","            new_df = pd.DataFrame(column_data_list)\n","            combined_df.drop(column_name, axis=1, inplace=True)\n","            combined_df = pd.concat([combined_df, new_df], axis=1)\n","\n","        return combined_df\n","\n","    def make_unique_column_names(self, df):\n","        \"\"\"\n","        데이터프레임의 컬럼명이 중복된 경우 고유한 컬럼명을 만들어줍니다.\n","\n","        Args:\n","            df (pandas.DataFrame): 중복된 컬럼명이 포함된 데이터프레임.\n","\n","        Returns:\n","            pandas.DataFrame: 컬럼명이 중복을 피한 데이터프레임.\n","        \"\"\"\n","        unique_columns = []\n","        for col in df.columns:\n","            if col in unique_columns:\n","                counter = 1\n","                new_col = f\"{col}_{counter}\"\n","                while new_col in unique_columns:\n","                    counter += 1\n","                    new_col = f\"{col}_{counter}\"\n","                unique_columns.append(new_col)\n","            else:\n","                unique_columns.append(col)\n","\n","        df.columns = unique_columns\n","        return df\n","\n","# Usage example:\n","folder_path = '/content/drive/MyDrive/요약 데이터/4.논문자료 요약'\n","data_processor = JSONDataProcessor(folder_path)\n","\n","combined_dataframe = data_processor.combine_json_files()\n","\n","columns_to_split = ['summary_entire', 'summary_section']\n","combined_dataframe = data_processor.extract_summary_columns(combined_dataframe, columns_to_split)\n","\n","combined_dataframe = data_processor.make_unique_column_names(combined_dataframe)\n","# 두 열(original, summary)을 세로로 쌓기\n","stacked_column_o = pd.concat([combined_dataframe['orginal_text'], combined_dataframe['orginal_text_1']], axis=0, ignore_index=True)\n","stacked_column_s = pd.concat([combined_dataframe['summary_text'], combined_dataframe['summary_text_1']], axis=0, ignore_index=True)\n","\n","# 쌓인 열을 사용하여 새 데이터 프레임 생성\n","data_논문 = pd.DataFrame({'original_text': stacked_column_o, 'summary_text': stacked_column_s})"]},{"cell_type":"code","source":["data_논문.to_csv('paper.csv')"],"metadata":{"id":"q1b9rVl7F8lJ","executionInfo":{"status":"ok","timestamp":1685633973122,"user_tz":-540,"elapsed":43702,"user":{"displayName":"서단우","userId":"02276360755929024305"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# 1.문서요약 텍스트"],"metadata":{"id":"ZOvfksT8m7u4"}},{"cell_type":"code","source":["def combine_json_files_recursive(folder_path):\n","    data_frames = []\n","\n","    # Traverse the directory recursively\n","    for root, dirs, files in os.walk(folder_path):\n","        for file_name in files:\n","            file_path = os.path.join(root, file_name)\n","\n","            # Check if the file is a JSON file\n","            if file_name.endswith('.json') and os.path.isfile(file_path):\n","                # Read JSON file into a DataFrame\n","                with open(file_path, 'r') as file:\n","                    json_data = json.load(file)\n","                    df = pd.DataFrame(json_data['documents'])\n","\n","                # Check for duplicate column names\n","                duplicates = df.columns[df.columns.duplicated()]\n","                for duplicate in duplicates:\n","                    # Add suffix to distinguish duplicate column names\n","                    suffix = 1\n","                    while duplicate + '_' + str(suffix) in df.columns:\n","                        suffix += 1\n","                    df.rename(columns={duplicate: duplicate + '_' + str(suffix)}, inplace=True)\n","\n","                # Append DataFrame to the list\n","                data_frames.append(df)\n","\n","    # Concatenate all DataFrames into a single DataFrame\n","    combined_df = pd.concat(data_frames, ignore_index=True)\n","    \n","    return combined_df\n","\n","folder_path = '1.문서요약 텍스트'\n","combined_df = combine_json_files_recursive(folder_path)\n","data_문서 = combined_df[['text','abstractive']]"],"metadata":{"id":"HtXSW1swkcdA","executionInfo":{"status":"ok","timestamp":1685634120048,"user_tz":-540,"elapsed":107808,"user":{"displayName":"서단우","userId":"02276360755929024305"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data_문서.to_csv('document.csv')"],"metadata":{"id":"TwJF1xyhrAQ0","executionInfo":{"status":"ok","timestamp":1685634297213,"user_tz":-540,"elapsed":162239,"user":{"displayName":"서단우","userId":"02276360755929024305"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# 2.도서자료 요약"],"metadata":{"id":"_TMLdZdAGKPQ"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"sLONJSul3ay1","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1685636134593,"user_tz":-540,"elapsed":16,"user":{"displayName":"서단우","userId":"02276360755929024305"}},"outputId":"68854266-a56c-4909-fe98-e0736b73e5b2"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ec9db663aecb>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2.도서자료 요약'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mcombined_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_json_files_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-ec9db663aecb>\u001b[0m in \u001b[0;36mcombine_json_files_recursive\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Traverse the directory recursively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_walk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_walk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36m_walk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def combine_json_files_recursive(folder_path):\n","    data_frames = []\n","\n","    # Traverse the directory recursively\n","    for root, dirs, files in os.walk(folder_path):\n","        for file_name in files:\n","            file_path = os.path.join(root, file_name)\n","\n","            # Check if the file is a JSON file\n","            if file_name.endswith('.json') and os.path.isfile(file_path):\n","                # Read JSON file into a DataFrame\n","                with open(file_path, 'r') as file:\n","                    json_data = json.load(file)\n","                    print(f\"File: {file_path}\")\n","                    print(f\"JSON Data: {json_data}\")\n","                    if isinstance(json_data, dict):\n","                        df = pd.DataFrame([json_data])  # Convert dictionary to DataFrame\n","                        df = df[['passage', 'summary']]  # Select desired columns\n","                        data_frames.append(df)\n","                    else:\n","                        print(f\"Invalid JSON data in file: {file_path}\")\n","            \n","    # Concatenate all DataFrames into a single DataFrame\n","    combined_df = pd.concat(data_frames, ignore_index=True)\n","    \n","    return combined_df\n","\n","\n","folder_path = '2.도서자료 요약'\n","combined_data = combine_json_files_recursive(folder_path)\n","\n","print(combined_data)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"mmRFN16vcs3y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VeX06BiBL4px"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1UjiCTBddgCyZyFerI7cS7o00rSJnNEQr","authorship_tag":"ABX9TyOHUcXYgO+DXu8WyA8jK2uY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}